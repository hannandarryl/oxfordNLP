{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical 1: word2vec\n",
    "<p>Oxford CS - Deep NLP 2017<br>\n",
    "https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/</p>\n",
    "<p>[Yannis Assael, Brendan Shillingford, Chris Dyer]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This practical is presented as an IPython Notebook, with the code written for recent versions of **Python 3**. The code in this practical will not work with Python 2 unless you modify it. If you are using your own Python installation, ensure you have a setup identical to that described in the installation shell script (which is intended for use with the department lab machines). We will be unable to support installation on personal machines due to time constraints, so please use the lab machines and the setup script if you are unfamiliar with how to install Anaconda.\n",
    "\n",
    "To execute a notebook cell, press `shift-enter`. The return value of the last command will be displayed, if it is not `None`.\n",
    "\n",
    "Potentially useful library documentation, references, and resources:\n",
    "\n",
    "* IPython notebooks: <https://ipython.org/ipython-doc/3/notebook/notebook.html#introduction>\n",
    "* Numpy numerical array library: <https://docs.scipy.org/doc/>\n",
    "* Gensim's word2vec: <https://radimrehurek.com/gensim/models/word2vec.html>\n",
    "* Bokeh interactive plots: <http://bokeh.pydata.org/en/latest/> (we provide plotting code here, but click the thumbnails for more examples to copy-paste)\n",
    "* scikit-learn ML library (aka `sklearn`): <http://scikit-learn.org/stable/documentation.html>\n",
    "* nltk NLP toolkit: <http://www.nltk.org/>\n",
    "* tutorial for processing xml in python using `lxml`: <http://lxml.de/tutorial.html> (we did this for you below, but in case you need it in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"40ba1c34-59fb-4d92-abc5-cc6c9f2496a2\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      Bokeh.$(\"#40ba1c34-59fb-4d92-abc5-cc6c9f2496a2\").text(\"BokehJS successfully loaded.\");\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"40ba1c34-59fb-4d92-abc5-cc6c9f2496a2\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '40ba1c34-59fb-4d92-abc5-cc6c9f2496a2' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.12.2.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#40ba1c34-59fb-4d92-abc5-cc6c9f2496a2\").text(\"BokehJS is loading...\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === \"1\") {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (!force) {\n",
       "      var cell = $(\"#40ba1c34-59fb-4d92-abc5-cc6c9f2496a2\").parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Download the TED dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the dataset if it's not already there: this may take a minute as it is 75MB\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For now, we're only interested in the subtitle text, so let's extract that from the XML:\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "input_text = '\\n'.join(doc.xpath('//content/text()'))\n",
    "del doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Preprocessing\n",
    "\n",
    "In this part, we attempt to clean up the raw subtitles a bit, so that we get only sentences. The following substring shows examples of what we're trying to get rid of. Since it's hard to define precisely what we want to get rid of, we'll just use some simple heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' baby does.\\n(Video) Hyowon Gweon: See this? (Ball squeaks) Did you see that? (Ball squeaks) Cool. See this one? (Ball squeaks) Wow.\\nLaura Schulz: Told you. (Laughs)\\n(Vide'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = input_text.find(\"Hyowon Gweon: See this?\")\n",
    "input_text[i-20:i+150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by removing all parenthesized strings using a regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text_noparens = re.sub(r'\\([^)]*\\)', '', input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify the same location in the text is now clean as follows. We won't worry about the irregular spaces since we'll later split the text into sentences and tokenize it anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hat the baby does.\\n Hyowon Gweon: See this?  Did you see that?  Cool. See this one?  Wow.\\nLaura Schulz: Told you. \\n HG: See this one?  Hey Clara, this one's for you. You \""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = input_text_noparens.find(\"Hyowon Gweon: See this?\")\n",
    "input_text_noparens[i-20:i+150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's attempt to remove speakers' names that occur at the beginning of a line, by deleting pieces of the form \"`<up to 20 characters>:`\", as shown in this example. Of course, this is an imperfect heuristic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Here are two reasons companies fail: they only do more of the same, or they only do what's new\",\n",
       " 'To me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation',\n",
       " ' Both are necessary, but it can be too much of a good thing',\n",
       " 'Consider Facit',\n",
       " \" I'm actually old enough to remember them\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_strings_ted = []\n",
    "for line in input_text_noparens.split('\\n'):\n",
    "    m = re.match(r'^(?:(?P<precolon>[^:]{,20}):)?(?P<postcolon>.*)$', line)\n",
    "    sentences_strings_ted.extend(sent for sent in m.groupdict()['postcolon'].split('.') if sent)\n",
    "\n",
    "# Uncomment if you need to save some RAM: these strings are about 50MB.\n",
    "# del input_text, input_text_noparens\n",
    "\n",
    "# Let's view the first few:\n",
    "sentences_strings_ted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have sentences, we're ready to tokenize each of them into words. This tokenization is imperfect, of course. For instance, how many tokens is \"can't\", and where/how do we split it? We'll take the simplest naive approach of splitting on spaces. Before splitting, we remove non-alphanumeric characters, such as punctuation. You may want to consider the following question: why do we replace these characters with spaces rather than deleting them? Think of a case where this yields a different answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_ted = []\n",
    "for sent_str in sentences_strings_ted:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
    "    sentences_ted.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two sample processed sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266694"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n"
     ]
    }
   ],
   "source": [
    "print(sentences_ted[0])\n",
    "print(sentences_ted[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Word Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you store the counts of the top 1000 words in a list called `counts_ted_top1000`, the code below will plot the histogram requested in the writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "freqdist = FreqDist([word for sentence in sentences_ted for word in sentence])\n",
    "most_common = freqdist.most_common(1000)\n",
    "\n",
    "counts_ted_top1000 = [aTuple[1] for aTuple in most_common]\n",
    "words_top_ted = [aTuple[0] for aTuple in most_common]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distribution of top-1000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"plotdiv\" id=\"6be8c60a-bdcc-40c4-ad67-5cea83155fee\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = \"\";\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "      window._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "      window._bokeh_timeout = Date.now() + 0;\n",
       "      window._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (window.Bokeh !== undefined) {\n",
       "        Bokeh.$(\"#6be8c60a-bdcc-40c4-ad67-5cea83155fee\").text(\"BokehJS successfully loaded.\");\n",
       "      } else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"6be8c60a-bdcc-40c4-ad67-5cea83155fee\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6be8c60a-bdcc-40c4-ad67-5cea83155fee' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        Bokeh.$(function() {\n",
       "            var docs_json = {\"7d0af367-6a7d-4c9b-9ef9-0b52ba44299c\":{\"roots\":{\"references\":[{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a98fdadf-bbe5-48b9-8aa6-44eb54747cf1\",\"type\":\"BasicTicker\"}},\"id\":\"91531569-d342-401d-9326-5366ebb5e929\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"201de79f-c225-4f5a-8396-7d40eaea8f8f\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"88bd574e-b6aa-44cf-9bbf-2a2723582449\",\"type\":\"BasicTicker\"}},\"id\":\"333f7364-5c56-4d49-a59a-1249417ed831\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"05ae9634-b300-45c0-9381-e78182a17aec\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"33d817b9-f6d4-43f1-82c1-53a67ccee70c\",\"type\":\"Quad\"},\"hover_glyph\":null,\"nonselection_glyph\":{\"id\":\"14fd8ef3-5708-421b-bce2-2b918d87f5b0\",\"type\":\"Quad\"},\"selection_glyph\":null},\"id\":\"44587b26-3a5b-4ca2-9252-04008e2ec72a\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"fed833c9-2287-40cc-a70c-8d5ae8ca0ef7\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"below\":[{\"id\":\"333f7364-5c56-4d49-a59a-1249417ed831\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"08c79bc3-8c51-4255-80c4-c4916860be00\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"333f7364-5c56-4d49-a59a-1249417ed831\",\"type\":\"LinearAxis\"},{\"id\":\"64e80633-3015-486b-ad26-f5ed95a20c5f\",\"type\":\"Grid\"},{\"id\":\"08c79bc3-8c51-4255-80c4-c4916860be00\",\"type\":\"LinearAxis\"},{\"id\":\"91531569-d342-401d-9326-5366ebb5e929\",\"type\":\"Grid\"},{\"id\":\"44587b26-3a5b-4ca2-9252-04008e2ec72a\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"43bc17cb-ef8b-4205-a139-0517526511cf\",\"type\":\"Title\"},\"tool_events\":{\"id\":\"251bd378-2348-4a51-b15c-c737f34b82fd\",\"type\":\"ToolEvents\"},\"toolbar\":{\"id\":\"17c19f36-c424-4a48-a0a0-bf81c9b47ceb\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"acda35d5-ebfa-455d-85f5-dce19af2af29\",\"type\":\"DataRange1d\"},\"y_range\":{\"id\":\"d1cdbd52-0b61-42d9-b3cd-e637dba962fb\",\"type\":\"DataRange1d\"}},\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"plot\":null,\"text\":\"Top-1000 words distribution\"},\"id\":\"43bc17cb-ef8b-4205-a139-0517526511cf\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"201de79f-c225-4f5a-8396-7d40eaea8f8f\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"fed833c9-2287-40cc-a70c-8d5ae8ca0ef7\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a98fdadf-bbe5-48b9-8aa6-44eb54747cf1\",\"type\":\"BasicTicker\"}},\"id\":\"08c79bc3-8c51-4255-80c4-c4916860be00\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"left\",\"right\",\"top\"],\"data\":{\"left\":[404.0,2477.44,4550.88,6624.32,8697.76,10771.2,12844.64,14918.08,16991.52,19064.96,21138.4,23211.84,25285.28,27358.72,29432.16,31505.600000000002,33579.04,35652.48,37725.92,39799.36,41872.8,43946.24,46019.68,48093.12,50166.56,52240.0,54313.44,56386.880000000005,58460.32,60533.76,62607.200000000004,64680.64,66754.08,68827.52,70900.96,72974.40000000001,75047.84,77121.28,79194.72,81268.16,83341.6,85415.04000000001,87488.48,89561.92,91635.36,93708.8,95782.24,97855.68000000001,99929.12,102002.56,104076.0,106149.44,108222.88,110296.32,112369.76000000001,114443.2,116516.64,118590.08,120663.52,122736.96,124810.40000000001,126883.84,128957.28,131030.72,133104.16,135177.6,137251.04,139324.48,141397.92,143471.36000000002,145544.80000000002,147618.24,149691.68,151765.12,153838.56,155912.0,157985.44,160058.88,162132.32,164205.76,166279.2,168352.64,170426.08000000002,172499.52000000002,174572.96,176646.4,178719.84,180793.28,182866.72,184940.16,187013.6,189087.04,191160.48,193233.92,195307.36000000002,197380.80000000002,199454.24,201527.68,203601.12,205674.56],\"right\":[2477.44,4550.88,6624.32,8697.76,10771.2,12844.64,14918.08,16991.52,19064.96,21138.4,23211.84,25285.28,27358.72,29432.16,31505.600000000002,33579.04,35652.48,37725.92,39799.36,41872.8,43946.24,46019.68,48093.12,50166.56,52240.0,54313.44,56386.880000000005,58460.32,60533.76,62607.200000000004,64680.64,66754.08,68827.52,70900.96,72974.40000000001,75047.84,77121.28,79194.72,81268.16,83341.6,85415.04000000001,87488.48,89561.92,91635.36,93708.8,95782.24,97855.68000000001,99929.12,102002.56,104076.0,106149.44,108222.88,110296.32,112369.76000000001,114443.2,116516.64,118590.08,120663.52,122736.96,124810.40000000001,126883.84,128957.28,131030.72,133104.16,135177.6,137251.04,139324.48,141397.92,143471.36000000002,145544.80000000002,147618.24,149691.68,151765.12,153838.56,155912.0,157985.44,160058.88,162132.32,164205.76,166279.2,168352.64,170426.08000000002,172499.52000000002,174572.96,176646.4,178719.84,180793.28,182866.72,184940.16,187013.6,189087.04,191160.48,193233.92,195307.36000000002,197380.80000000002,199454.24,201527.68,203601.12,205674.56,207748.0],\"top\":[0.0003892082722432286,3.327803071224632e-05,1.3504128404969522e-05,8.681225403194689e-06,8.198935103017207e-06,5.305193301952315e-06,4.340612701597344e-06,1.929161200709931e-06,2.893741801064899e-06,1.929161200709929e-06,9.645806003549663e-07,9.645806003549663e-07,1.929161200709929e-06,4.822903001774831e-07,9.645806003549646e-07,4.822903001774831e-07,0.0,4.82290300177484e-07,0.0,0.0,0.0,0.0,0.0,4.82290300177484e-07,0.0,0.0,0.0,4.82290300177484e-07,0.0,0.0,4.82290300177484e-07,0.0,4.822903001774823e-07,0.0,4.822903001774823e-07,4.822903001774857e-07,0.0,4.822903001774823e-07,0.0,4.822903001774823e-07,0.0,0.0,0.0,0.0,0.0,4.822903001774823e-07,0.0,0.0,0.0,0.0,4.822903001774823e-07,0.0,0.0,0.0,0.0,4.822903001774823e-07,0.0,0.0,0.0,0.0,4.822903001774857e-07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.822903001774823e-07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.822903001774823e-07]}},\"id\":\"05ae9634-b300-45c0-9381-e78182a17aec\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"plot\":{\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"df0fa4b2-19fb-4d17-8c40-9f6f1c1d0996\",\"type\":\"PanTool\"},{\"attributes\":{\"plot\":{\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"fc7e267a-75fd-40bc-95cb-6005cdc59923\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null},\"id\":\"acda35d5-ebfa-455d-85f5-dce19af2af29\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":{\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"88bd574e-b6aa-44cf-9bbf-2a2723582449\",\"type\":\"BasicTicker\"}},\"id\":\"64e80633-3015-486b-ad26-f5ed95a20c5f\",\"type\":\"Grid\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"14fd8ef3-5708-421b-bce2-2b918d87f5b0\",\"type\":\"Quad\"},{\"attributes\":{\"plot\":{\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"3bfd15ff-2c1a-4f7d-b01d-a36f246bba6f\",\"type\":\"SaveTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"df0fa4b2-19fb-4d17-8c40-9f6f1c1d0996\",\"type\":\"PanTool\"},{\"id\":\"f99227cf-cde1-41fa-9e90-2968000bed91\",\"type\":\"WheelZoomTool\"},{\"id\":\"fc7e267a-75fd-40bc-95cb-6005cdc59923\",\"type\":\"ResetTool\"},{\"id\":\"3bfd15ff-2c1a-4f7d-b01d-a36f246bba6f\",\"type\":\"SaveTool\"}]},\"id\":\"17c19f36-c424-4a48-a0a0-bf81c9b47ceb\",\"type\":\"Toolbar\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"#1f77b4\"},\"left\":{\"field\":\"left\"},\"line_color\":{\"value\":\"#555555\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"top\"}},\"id\":\"33d817b9-f6d4-43f1-82c1-53a67ccee70c\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"251bd378-2348-4a51-b15c-c737f34b82fd\",\"type\":\"ToolEvents\"},{\"attributes\":{\"callback\":null},\"id\":\"d1cdbd52-0b61-42d9-b3cd-e637dba962fb\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"a98fdadf-bbe5-48b9-8aa6-44eb54747cf1\",\"type\":\"BasicTicker\"},{\"attributes\":{\"plot\":{\"id\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"f99227cf-cde1-41fa-9e90-2968000bed91\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"88bd574e-b6aa-44cf-9bbf-2a2723582449\",\"type\":\"BasicTicker\"}],\"root_ids\":[\"0e0291bf-37cc-46f3-a1aa-604666b97792\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.2\"}};\n",
       "            var render_items = [{\"docid\":\"7d0af367-6a7d-4c9b-9ef9-0b52ba44299c\",\"elementid\":\"6be8c60a-bdcc-40c4-ad67-5cea83155fee\",\"modelid\":\"0e0291bf-37cc-46f3-a1aa-604666b97792\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "        });\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i](window.Bokeh);\n",
       "        }if (force === \"1\") {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!window._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        window._bokeh_failed_load = true;\n",
       "      } else if (!force) {\n",
       "        var cell = $(\"#6be8c60a-bdcc-40c4-ad67-5cea83155fee\").parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, edges = np.histogram(counts_ted_top1000, density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"Top-1000 words distribution\")\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot sort vocabulary after model weights already initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-545d7518f42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_ted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwords_top_ted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/darrylhannan/anaconda3/lib/python3.5/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36msort_vocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;34m\"\"\"Sort the vocabulary so the most frequent words have the lowest indexes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot sort vocabulary after model weights already initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot sort vocabulary after model weights already initialized."
     ]
    }
   ],
   "source": [
    ">>> model_ted = Word2Vec(sentences_ted, size=100, window=5, min_count=10, workers=4).sort_vocab()\n",
    "words_top_ted = model_ted.vocab[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Ted Learnt Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding similar words: (see gensim docs for more functionality of `most_similar`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.854941725730896),\n",
       " ('guy', 0.8115435242652893),\n",
       " ('lady', 0.78350830078125),\n",
       " ('boy', 0.7540330290794373),\n",
       " ('girl', 0.7465856075286865),\n",
       " ('gentleman', 0.7265521287918091),\n",
       " ('soldier', 0.7216047048568726),\n",
       " ('kid', 0.6818109154701233),\n",
       " ('david', 0.6759620904922485),\n",
       " ('photographer', 0.654590368270874)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ted.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('software', 0.7446777820587158),\n",
       " ('machine', 0.7194404602050781),\n",
       " ('robot', 0.7009714245796204),\n",
       " ('device', 0.6996128559112549),\n",
       " ('3d', 0.6844081878662109),\n",
       " ('program', 0.6556263566017151),\n",
       " ('camera', 0.6524646282196045),\n",
       " ('circuit', 0.6517256498336792),\n",
       " ('interface', 0.625410258769989),\n",
       " ('video', 0.624533474445343)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ted.most_similar(\"computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harmony', 0.6134402751922607),\n",
       " ('security', 0.5975061655044556),\n",
       " ('democracy', 0.5785027742385864),\n",
       " ('bank', 0.5756847858428955),\n",
       " ('war', 0.5740978121757507),\n",
       " ('forum', 0.5740069150924683),\n",
       " ('criminal', 0.5721709728240967),\n",
       " ('democratic', 0.5597155094146729),\n",
       " ('elsewhere', 0.5591738820075989),\n",
       " ('justice', 0.5544170141220093)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_ted.most_similar(\"peace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE visualization\n",
    "To use the t-SNE code below, first put a list of the top 1000 words (as strings) into a variable `words_top_ted`. The following code gets the corresponding vectors from the model, assuming it's called `model_ted`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'to', 'of', 'a', 'that', 'i', 'in', 'it', 'you', 'we', 'is', 's', 'this', 'so', 'they', 'was', 'for', 'are', 'have', 'but', 'what', 'on', 'with', 'can', 't', 'about', 'there', 'be', 'as', 'at', 'all', 'not', 'do', 'my', 'one', 're', 'people', 'like', 'if', 'from', 'now', 'our', 'he', 'an', 'just', 'these', 'or', 'when', 'because', 'very', 'me', 'out', 'by', 'them', 'how', 'know', 'up', 'going', 'had', 'more', 'think', 'who', 'were', 'see', 'your', 'their', 'which', 'would', 'here', 'really', 'get', 've', 'then', 'm', 'world', 'us', 'time', 'some', 'has', 'don', 'actually', 'into', 'way', 'where', 'will', 'years', 'things', 'other', 'no', 'could', 'go', 'well', 'want', 'been', 'make', 'right', 'she', 'said', 'something', 'those', 'first', 'two', 'than', 'much', 'also', 'look', 'new', 'thing', 'little', 'got', 'back', 'over', 'most', 'say', 'even', 'his', 'life', 'only', 'work', 'many', 'take', 'need', 'did', 'lot', 'kind', 'why', 'good', 'around', 'every', 'different', 'down', 'll', 'let', 'her', 'through', 'same', 'being', 'come', 'd', 'day', 'year', 'three', 'use', 'doing', 'put', 'called', 'any', 'today', 'percent', 'made', 'after', 'thank', 'tell', 'great', 'human', 'find', 'didn', 'fact', 'talk', 'change', 'started', 'another', 'idea', 'big', 'last', 'own', 'before', 'its', 'never', 'should', 'better', 'give', 'thought', 'went', 'might', 'important', '000', 'again', 'together', 'able', 'still', 'problem', 'off', 'next', 'part', 'course', 'system', 'him', 'does', 'each', 'start', 'show', 'long', 'ago', 'story', 'came', 'brain', 'few', 'bit', 'between', 'used', 'place', 'technology', 'women', 'too', 'old', 'mean', 'data', 'water', 'looking', 'question', 'maybe', 'found', 'love', 'doesn', 'end', 'example', '10', 'done', 'point', 'four', 'real', 'wanted', 'ever', 'understand', 'school', 'sort', 'live', 'call', 'whole', 'children', 'always', 'trying', 'may', 'person', 'away', 'believe', 'feel', 'try', 'million', 'working', 'help', 'everything', 'five', 'country', 'thinking', 'second', 'using', 'information', 'money', 'means', 'power', 'took', 'times', 'high', 'space', 'number', 'kids', 'home', 'become', 'create', 'small', 'design', 'making', 'best', 'left', 'getting', 'future', 'enough', 'man', 'quite', 'city', 'without', 'sense', 'happened', 'comes', 'social', 'probably', 'light', 'less', 'talking', 'energy', 'am', 'building', 'science', 'food', 'body', 'told', 'interesting', 'ask', 'half', 'pretty', 'hard', 'play', 'anything', 'lives', 'countries', 'coming', 'such', 'family', 'stuff', 'dollars', 'moment', 'earth', '20', 'imagine', 'across', 'side', 'saw', 'while', 'happen', 'once', 'okay', 'build', 'having', 'men', 'later', 'experience', 'asked', 'makes', 'living', 'seen', 'says', 'room', 'hand', 'simple', 'health', 'ways', 'else', 'case', 'almost', 'yet', 'young', 'days', 'nothing', 'bad', 'care', 'happens', 'goes', 'move', 'states', 'reason', 'computer', 'open', 'africa', 'learn', 'process', 'inside', 'someone', 'six', 'far', 'project', 'mind', 'remember', 'single', 'picture', 'both', 'whether', 'problems', 'community', 'saying', 'basically', 'already', 'within', 'looked', 'myself', 'billion', 'possible', 'often', 'business', 'planet', 'global', 'top', 'everybody', 'public', 'sure', 'set', 'wrong', 'book', 'car', 'keep', 'answer', 'yes', 'oh', 'hope', 'sometimes', 'history', 'true', 'war', 'guy', 'child', 'instead', 'months', 'ideas', 'looks', 'matter', 'government', 'amazing', 'united', 'since', 'cells', 'bring', 'age', 'job', 'heard', 'until', 'face', 'wasn', '100', 'read', 'control', 'isn', 'research', '30', 'words', 'u', 'group', 'under', 'self', 'somebody', 'built', 'state', 'woman', 'turn', 'friends', 'beautiful', 'line', 'knew', 'couple', 'order', 'form', 'yeah', 'internet', 'middle', 'music', 'piece', 'nature', 'head', 'though', 'stop', 'everyone', '50', 'places', 'video', 'learned', 'language', 'run', 'night', 'decided', 'study', 'word', 'cancer', 'taking', 'works', 'became', 'exactly', 'species', 'completely', 'society', 'education', 'against', 'stories', 'large', 'share', 'level', 'heart', 'america', 'model', 'gets', 'questions', 'mother', 'god', 'company', 'turns', 'ourselves', 'happening', 'hear', 'art', 'themselves', 'must', 'itself', 'kinds', 'rather', 'students', 'name', 'hours', 'disease', 'front', 'house', 'couldn', 'huge', 'created', 'universe', 'ok', 'animals', 'american', 'environment', 'worked', 'minutes', 'ones', 'black', 'perhaps', '1', 'past', 'third', 'along', 'others', 'finally', 'early', 'sound', 'game', 'thousands', 'century', 'least', 'based', 'per', 'ted', 'lots', 'figure', 'free', 'particular', 'guys', 'happy', 'news', 'learning', 'entire', 'won', 'gave', 'india', 'machine', 'during', 'systems', 'air', 'difference', 'outside', 'natural', 'taken', 'seven', 'changed', 'given', 'leave', 'cell', '15', 'close', 'cities', 'behind', 'full', 'scale', 'china', 'difficult', 'takes', 'companies', 'area', 'yourself', 'reality', 'seeing', 'easy', 'turned', 'cost', 'eyes', 'team', 'moving', 'population', 'culture', 'york', 'hands', 'whatever', 'began', 'needs', 'terms', 'image', 'needed', 'simply', 'beginning', 'father', 'local', 'realized', 'media', 'death', 'parents', 'walk', 'view', 'white', 'market', 'parts', 'ocean', 'economic', 'eight', 'powerful', 'week', 'known', 'size', 'felt', 'humans', 'certain', 'spend', 'longer', 'phone', 'wonderful', 'cannot', 'grow', 'common', 'tried', 'center', 'fish', 'land', 'oil', 'political', 'deal', 'interested', 'red', 'gone', 'amount', 'weeks', 'spent', 'opportunity', 'lost', 'paper', 'national', 'quickly', 'blue', 'step', 'poor', 'green', 'buy', 'wouldn', 'growth', 'either', 'patients', 'sitting', 'ability', 'changes', 'write', 'south', 'challenge', 'low', 'friend', 'growing', 'field', 'shows', '2', 'rest', 'born', 'climate', '40', 'test', 'street', 'incredible', 'surface', 'average', 'morning', 'physical', 'pay', 'scientists', 'value', 'program', 'feeling', 'girl', 'met', 'hundreds', 'behavior', 'economy', 'dna', 'complex', 'access', 'risk', 'animal', 'structure', 'feet', 'attention', 'areas', 'anyone', 'deep', 'watch', 'short', 'absolutely', 'speak', 'brought', 'bottom', 'die', 'audience', 'numbers', 'stage', 'realize', 'law', 'images', 'wrote', 'understanding', 'knowledge', 'books', 'literally', 'movement', 'giving', 'ground', 'eat', 'force', 'seems', 'alone', 'telling', 'hold', 'starting', 'nice', 'forward', 'sea', 'developed', 'individual', 'kid', 'millions', 'support', 'tools', 'running', 'miles', 'online', 'result', 'technologies', 'medical', 'act', 'north', 'lab', 'development', 'blood', 'fear', 'nobody', 'map', 'personal', 'issue', 'voice', 'material', 'key', 'recently', '12', 'theory', 'cut', 'cars', 'fast', 'sun', 'changing', 'clear', 'playing', 'especially', 'soon', 'girls', 'patient', 'choice', 'fly', 'creating', 'relationship', 'normal', 'talked', 'europe', 'discovered', 'gives', 'generation', 'dark', 'type', 'showed', 'industry', 'asking', 'chance', 'seem', 'rate', 'designed', 'hour', 'fun', 'issues', 'color', 'innovation', 'university', 'class', 'computers', 'several', 'tiny', 'english', 'save', 'focus', 'allow', 'developing', 'solve', 'digital', 'film', 'network', 'special', 'wall', 'situation', 'baby', 'solution', 'box', 'knows', 'reasons', 'stand', 'dead', 'meet', 'anybody', 'begin', 'haven', 'impact', 'term', 'pictures', 'beyond', 'please', 'ice', 'produce', 'shape', 'non', 'resources', 'cool', 'robot', 'likely', 'groups', 'stay', 'major', 'rights', 'truth', 'available', 'obviously', 'writing', 'cause', 'evidence', 'experiment', 'modern', 'drug', 'becomes', 'incredibly', 'bigger', 'guess', 'aren', 'nine', 'drugs', 'product', 'lived', 'involved', 'perfect', 'month', 'google', 'effect', 'similar', 'putting', 'eye', 'pick', 'message', 'quality', 'web', 'violence', 'evolution', 'office', 'security', 'basic', 'indeed', 'general', 'solar', 'towards', 'drive', 'present', 'worth', 'send', 'listen', 'revolution', 'explain', 'hundred', 'died', 'certainly', 'teach', 'ready', '25', 'journey', 'walking', 'hit', 'led', 'international', 'approach', '200', 'scientific', 'games', 'communities', 'potential', 'crazy', 'chinese', '60', 'device', 'source', 'camera', 'sex', 'carbon', 'rules', 'sounds', 'boy', 'reach', 'starts', 'west', 'examples', '3', 'particularly', 'success', 'measure', 'software', 'totally', 'suddenly', 'action', 'college', 'higher', 'code', 'eventually', 'democracy', 'among', 'minute', 'sit', 'largest', 'showing', 'hospital', 'period', 'notice', 'develop', 'mass', 'dream', 'onto', 'memory', 'add', 'break', 'plants', 'zero', 'favorite', '11', 'everywhere', 'speed', 'response', 'schools', 'moved', 'wants', 'table', 'individuals', 'wait', 'extremely', 'movie', 'follow', 'anyway', 'trust', 'medicine', 'biggest', 'plant', 'watching', 'organization', 'creative', 'road', 'choose', 'worse', 'lead', 'results', '500', 'exciting', 'materials', 'grew', 'jobs', 'east', 'positive', 'poverty', 'plan', 'fall', 'safe', 'strong', 'essentially', 'object', 'door', 'happiness', 'son', 'continue', 'further', 'vision', 'student', 'doctor', 'named', 'role', 'objects', 'including', 'extraordinary', 'standing', 'skin', 'leaders', 'projects', 'usually', 'african', 'conversation', 'allowed', 'models', 'supposed', 'interest', 'faster', 'police', 'families', 'fight', 'connected', 'tree', 'cases', '5', 'screen', 'somewhere', 'goal', 'shown', 'buildings', 'finding']\n"
     ]
    }
   ],
   "source": [
    "# This assumes words_top_ted is a list of strings, the top 1000 words\n",
    "words_top_vec_ted = model_ted[words_top_ted]\n",
    "print(words_top_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-3d87de347c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwords_top_ted_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_top_vec_ted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/darrylhannan/anaconda3/lib/python3.5/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \"\"\"\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/darrylhannan/anaconda3/lib/python3.5/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    775\u001b[0m                           \u001b[0mX_embedded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                           \u001b[0mneighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                           skip_num_points=skip_num_points)\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     def _tsne(self, P, degrees_of_freedom, n_samples, random_state,\n",
      "\u001b[0;32m/Users/darrylhannan/anaconda3/lib/python3.5/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, random_state, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'it'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[t-SNE] Error after %d iterations: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/darrylhannan/anaconda3/lib/python3.5/site-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, objective_error, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, min_error_diff, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mnew_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/darrylhannan/anaconda3/lib/python3.5/site-packages/scipy/linalg/misc.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(a, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Differs from numpy only in non-finite handling and the use of blas.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# Only use optimized norms if axis and keepdims are not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/darrylhannan/anaconda3/lib/python3.5/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1215\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m   1216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "words_top_ted_tsne = tsne.fit_transform(words_top_vec_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE for most common words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_top_ted_tsne[:,0],\n",
    "                                    x2=words_top_ted_tsne[:,1],\n",
    "                                    names=words_top_ted))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Wiki Learnt Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('wikitext-103-raw-v1.zip'):\n",
    "    urllib.request.urlretrieve(\"https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip\", filename=\"wikitext-103-raw-v1.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('wikitext-103-raw-v1.zip', 'r') as z:\n",
    "    input_text = str(z.open('wikitext-103-raw/wiki.train.raw', 'r').read(), encoding='utf-8') # Thanks Robert Bastian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess sentences (note that it's important to remove small sentences for performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_wiki = []\n",
    "for line in input_text.split('\\n'):\n",
    "    s = [x for x in line.split('.') if x and len(x.split()) >= 5]\n",
    "    sentences_wiki.extend(s)\n",
    "    \n",
    "for s_i in range(len(sentences_wiki)):\n",
    "    sentences_wiki[s_i] = re.sub(\"[^a-z]\", \" \", sentences_wiki[s_i].lower())\n",
    "    sentences_wiki[s_i] = re.sub(r'\\([^)]*\\)', '', sentences_wiki[s_i])\n",
    "del input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample 1/5 of the data\n",
    "shuffle(sentences_wiki)\n",
    "print(len(sentences_wiki))\n",
    "sentences_wiki = sentences_wiki[:int(len(sentences_wiki)/5)]\n",
    "print(len(sentences_wiki))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, repeat all the same steps that you performed above. You should be able to reuse essentially all the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This assumes words_top_wiki is a list of strings, the top 1000 words\n",
    "words_top_vec_wiki = model_wiki[words_top_wiki]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "words_top_wiki_tsne = tsne.fit_transform(words_top_vec_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE for most common words\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=words_top_wiki_tsne[:,0],\n",
    "                                    x2=words_top_wiki_tsne[:,1],\n",
    "                                    names=words_top_wiki))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
